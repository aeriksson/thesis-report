\chapter{Background}
\label{ch:background}

In this chapter the subject of anomaly detection is briefly introduced, along with a discussion of some of the major challenges in anomaly detection research. Finally, the task of finding appropriate anomaly detection methods for a given application is formulated as an optimisation problem.

\section{Anomaly detection}
\label{sect:adb}

In essence, anomaly detection is the task of automatically detecting items (\emph{anomalies}) in datasets that in some sense do not fit in with the rest of those datasets (i.e.\ items that are \emph{anomalous} with regard to the rest of the data). The nature of both the datasets and anomalies are dependent on the specific application in which anomaly detection is applied, and vary drastically between application domains. As an illustration of this, consider the two datasets shown in Figures~\ref{fig:example1} and~\ref{fig:example1}. While these are similar in the sense that they both involve sequences, they differ in the type of data points (real-valued vs.\ categorical), the structure of the dataset (a long sequence vs.\ several sequences), as well as the nature of the anomalies (a subsequence vs.\ one sequence out of many).

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{resources/anomaly_example}
    \caption{\small Real-valued sequence with an anomaly at the center.}
    \vspace{-0pt}
\label{fig:example2}
\end{figure}

Like many other concepts in machine learning and data science, the term `anomaly detection' does not refer to any single well-defined problem. Rather, it is an umbrella term encompassing a collection of loosely related techniques and problems. Anomaly detection problems are encountered in nearly every domain in business and science in which data is collected for analysis. Naturally, this leads to a great diversity in the applications and implications of anomaly detection techniques. Due to this wide scope, anomaly detection is continuously being applied to new domains despite having been researched for decades.

\begin{figure}[htb]
    \centering
    \begin{tabular}{| l | l l l l l l l l |}
        \hline
        $\mathbf{S_1}$ & login & passwd & mail & ssh & \dots & mail & web & logout \\ \hline
        $\mathbf{S_2}$ & login & passwd & mail & web & \dots & web & web & logout \\ \hline
        $\mathbf{S_3}$ & login & passwd & mail & ssh & \dots & web & web & logout \\ \hline
        $\mathbf{S_4}$ & login & passwd & web & mail & \dots & web & mail & logout \\ \hline
        $\mathbf{S_5}$ & login & passwd & login & passwd & login & passwd & \dots & logout \\\hline
    \end{tabular}
    \caption{Several sequences of user commands. The bottom sequence is anomalous compared to the others.}
\label{fig:example1}
\end{figure}

In other words, anomaly detection as a subject encompasses a diverse set of problems, methods, and applications. Different anomaly detection problems and methods often share few similarities, and no unifying theory exists. Indeed, the eventual discovery of such a theory seems highly unlikely, considering the subjectivity inherent to most anomaly detection problems. Even the term `anomaly detection' itself has evaded any widely accepted definition~\cite{hodge} in spite of multiple attempts.

Despite this diversity, anomaly detection problems from different domains often share some structure, and studying anomaly detection as a subject can be useful as a means of understanding and exploiting such common structure. Anomaly detection methods are vital analysis tools in a wide variety of domains, and the set of scientific and commercial domains which could benefit from improved anomaly detection methods is huge. Indeed, due to increasing data volumes, exhaustive manual analysis is (or will soon be) prohibitively expensive in many domains, rendering effective automated anomaly detection critical to future development.

As a consequence of the diversity of the subject, a thorough survey of existing methods would not fit within the scope of this report. The interested reader is instead referred to any of several published surveys~\cite{hodge}~\cite{bakar}~\cite{chandola}~\cite{agyemang} and books~\cite{barnett}~\cite{hawkins}~\cite{leroy}.

A few classifications, which are useful in reasoning about anomaly detection problems, are now presented.

\subsection{Training data}
\label{sect:training_data}

As is customary in most areas of machine learning, anomaly detection problems are classified as either \emph{supervised}, \emph{semi-supervised} or \emph{unsupervised}~\footnote{Note that we here adopt the convention used in~\cite{chandola}, and take supervised learning to mean that both classes of training data are available, and semi-supervised to mean that only one class of training data is available. Conventionally, supervised learning is usually taken to mean any learning from training data, while semi-supervised learning is taken to mean that both labeled and unlabeled data is available.} based on the availability of training data.

In \emph{supervised} anomaly detection, training data containing both normal and anomalous items is available. In essence, this constitutes a traditional supervised classification problem. As such, it can be handled by any two-class classifier, such as regular support vector machines. Unfortunately, supervised approaches are usually not suitable for anomaly detection, for a few reasons. First, anomalous training data is almost always relatively scarce, potentially leading to skewed classes (described in~\cite{phua} and~\cite{joshi}). Second, supervised anomaly detection methods are by definition unable to detect types on anomalies that are not represented in the training data, and so can not be used to find \emph{novel} anomalies. This is problematic as it is often not possible to obtain training data containing all possible anomalies.

\begin{wrapfigure}{o}{0.5\textwidth}
    \changecaptionwidth
    \captionwidth{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{resources/supervision}
    \caption{Euler diagram of the available training data for the four types of supervision.}
\label{fig:supervision}
\end{wrapfigure}

\emph{Semi-supervised} anomaly detection, on the other hand, assumes the availability of only one class of training data. While anomaly detection with only anomalous training data has been discussed (for instance in~\cite{dasgupta}), the vast majority of semi-supervised methods assume that normal training data is available. Considering the difficulties involved in obtaining anomalous training data mentioned above, this should not be surprising. Semi-supervised methods are used more frequently than supervised methods in part due to the relative ease of producing normal training data to anomalous training data.

Finally, \emph{unsupervised} anomaly detection requires no training dataset. Since training data is not always available, unsupervised methods are typically considered to be of wider applicability than both supervised and semi-supervised methods~\cite{chandola}. However, unsupervised methods are unsuitable for certain tasks. Since training data can not be manually specified, it is more difficult to sift out uncommon but uninteresting items in unsupervised anomaly detection than in semi-supervised anomaly detection. Furthermore, unsupervised methods will not detect anomalies that are common but unexpected (although such items are arguably not anomalies by definition).

\subsection{Anomaly types}
\label{sect:anomaly_types}

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=1\textwidth]{resources/types_of_anomalies}
    \end{center}
    \caption{{\small Different types of anomalies in a real-valued continuous sequence. In the middle of each series is an aberration---colored black---corresponding to a specific type of anomaly. Appropriate contexts for these anomalies are colored red, while items not part of the contexts are colored grey. The top panel contains a point anomaly---a point anomalous with regard to all other points in the series. The second panel contains a contextual anomaly---a point anomalous with regard to its context (in this case, the few points preceding and succeeding it), but not necessarily to the entire series. The third panel contains a collective anomaly---a subsequence anomalous with regard to the rest of the time series. The fourth contains a contextual collective anomaly---a subsequence anomalous with regard to its context.}}
\label{fig:anomaly_types}
\end{figure}

It is also useful to classify problems based on what types of anomalies they can be used to detect. To this end, we now describe four \emph{anomaly types}~\footnote{While the concept of an anomaly type as defined here is novel, it is based on the concepts of contextual and collective anomalies discussed in~\cite{chandola}.}, which can be used to classify the types of anomalies handled by problems. In order of increasing generality, these are \emph{point anomalies}, \emph{contextual point anomalies}, \emph{collective anomalies}, and \emph{contextual collective anomalies}. An illustration of these anomaly types in the context of real-valued sequences is shown in Figure~\ref{fig:anomaly_types}.

\emph{Point anomalies} is the simplest of the anomaly types. These correspond to single points in the dataset that are considered anomalous with regard to the entire training set. Point anomalies are often referred to as \emph{outliers} and arise in many domains~\cite{eskin}. Compared to the other anomaly types, detecting point anomalies is relatively straightforward. Statistical anomaly measures have been shown to be well suited for handling point anomalies, and are often used. Essentially, point anomalies are the only anomaly type it makes sense to look for when the individual elements of the input dataset are unrelated.

When the individual elements of the input dataset \emph{are} related (for instance, through an ordering or a metric), however, not all interesting anomalies will be point anomalies. The concept of \emph{contextual point anomalies} generalises point anomalies to take context into account, and is thus better suited for such cases. We here take the context to be the set of items with which an item is compared; when the input dataset admits a concept of proximity, the context of an item is usually those items which are closest to that item. Contextual anomalies are defined as individual items that are anomalous with regards to their context; i.e.\ while they might seem normal when compared with all elements in the training data, they are anomalous when compared to the other items in their context. Formally, contextual point anomalies can be defined as follows: Given a dataset $D$ and a context function $C(d)$ which associates a context with each $d \in D$, a contextual point anomaly $d$ is a point anomaly in $C(d)$. Thus, contextual point anomalies are a generalisation of point anomalies, in the sense that a point anomaly is a contextual point anomaly with regard to the trivial context $C(d) = D \setminus {d}$.

Of course, detecting individual anomalous points $d \in D$ might not always suffice, and the concept of \emph{collective anomalies} might be required to capture relevant anomalies. Collective anomalies correspond to subsets of the input data that, when taken as a whole, are anomalous with regards to the entire training set. The task of detecting such anomalies can be formulated with the help of filter functions, which are map an input dataset $D$ to a set of candidate anomalies $F(D)$ (where $\forall f_i \in F(D): f_i \subset D$). Formally, given a set $D$ and a filter $F$, the collective anomalies of $D$ are the point anomalies of $F(D)$. Of course, point anomalies are a special case of collective anomalies, corresponding to the case where $F(D) = \{D\}$.

Finally, the concept of \emph{contextual collective anomalies}, which generalises contextual point anomalies and collective anomalies, can be introduced. Contextual collective anomalies correspond to subsets of the input dataset that are anomalous with regard to their context. Formally, given a dataset $D$, a filter $F$, and a context function $C$, the contextual collective anomalies of $D$ are the elements of $X \in F(D)$ that are point anomalies in $C(X)$. As expected, all of the three previous anomaly types can be considered special cases of contextual collective anomalies.

An illustration of the above concepts in real-valued sequences is shown in Figure~\ref{fig:anomaly_types}. Assuming that unsupervised anomaly detection is used, Detecting point anomalies amounts to disregarding the information provided by the ordering and detecting only `rare' items. While the task can capture the aberration in the first sequence in Figure~\ref{fig:anomaly_types}, none of the aberrations in the other sequences would be considered point anomalies.

While the value at the anomalous point at the center of the second sequence occurs elsewhere in that sequence, it is anomalous with regards to its context, and as such, should be considered a contextual point anomaly and can be captured by problem formulations that use contextual point anomalies.

Since the third time series is continuous, the aberration present at its center can not be a (contextual) point anomaly. It is, however, a collective anomaly, and can be accurately captured by problem formulations that use collective anomalies.

Finally, neither of the first three types of anomalies can capture the aberration in the fourth sequence, as it is both continuous and occurs elsewhere in the sequence. However, with an appropriate choice of context, it can be deemed a contextual collective anomaly, and can be captured by problem formulations that use contextual collective anomalies.

It should be noted that while contextual point anomalies, collective anomalies, and contextual collective anomalies are all generalisations of point anomalies, it is sometimes possible to reduce each of these anomaly types to of point anomalies, as well. As outlined above, each of these anomaly types can be defined using point anomalies. Furthermore, data normalisation be utilized to solve some contextual anomaly detection problems using point anomaly detection (see~\cite{meckesheimer}, for instance).

\section{On Anomaly Detection Research}
\label{sect:on_ad_research}

Most anomaly detection research involves either applying existing methods to new applications (i.e.\ on new types of data) or investigating new methods in the context of previously studied applications. In order to handle the increasing need for effective anomaly detection in many areas of business and science it is vital that these activities can be performed in a highly automated manner. However, little work has been done on developing automated methods and tools for anomaly detection research.

There are a few difficulties which complicate research into anomaly detection for new applications. For one, comparing different anomaly detection methods found in the literature is difficult, since even though it might not appear so at first glance, papers on anomaly detection often target subtly different problems. This renders direct comparisons problematic and makes it hard to assess which methods might be appropriate to use in new applications. A systematic way of comparing anomaly detection methods would be helpful in mitigating this problem.

Furthermore, reproducing existing results as well as applying existing methods to new datasets is often difficult. Due in part to the subjective nature of the subject, and in part to a historical lack of freely available datasets, new methods are often not adequately compared to previous methods. Furthermore, the performance of many anomaly detection methods is often highly dependent on parameter choices, and only the results for the best parameter values (which might be difficult to find) are often presented~\cite{keogh5}. Finally, there is often a lack of freely available software implementations of methods.

An important distinction to make is that between problems and methods. Informally, the process of finding an appropriate anomaly detection method for some application can be described as a two-step process. As a first step, an appropriate problem is formulated, which accurately captures intuitive notions of what constitutes an anomaly in the specific application. Once such a problem formulation has been found, an efficient method of solving or finding approximate solutions to the problem is constructed.

Due to the subjective nature of anomaly detection, radically different problem formulations might be appropriate for applications that are superficially very similar. Furthermore, there is often no obvious connection between the intuitive notion of what constitutes an anomaly in some application and the problem formulations which most accurately capture that notion, so prospective problem formulations must themselves be empirically evaluated.

This means that unless specific information is available on what problems are appropriate for a given application, finding the correct problem formulations should take priority over formulating methods. Finding efficient methods should be done only after it has been shown that the problem the methods are solving is relevant to the application. In the literature, methods, rather than problems, are often emphasised, and it can often be unclear exactly what problem a given method is meant to solve. In this report, the focus is instead placed almost entirely on problems.

This work attempts to simplify the research process by providing tools which help address the hurdles described above. As a means of mitigating the first problem, a general framework for systematically comparing anomaly detection problem formulations is presented, the purpose of which is to facilitate high-level reasoning about anomaly detection problems, and which thereby can help simplify the application of existing methods to new domains.

Furthermore, the process of finding appropriate anomaly detection methods for a given application is studied as an optimisation problem. A software implementation of this optimisation problem for anomaly detection in real-valued sequences is presented, which can help mitigate the reproducibility issues outlined above, as well as streamline the research process by enabling researchers to automatically evaluate a large amount of problem formulations.

\section{Problem formulation}
\label{sect:problem_formulation}
As a first step towards the goal of automated tools for anomaly detection research, the task we are trying to automateâ€“--that of finding appropriate anomaly detection methods for some given application---must be formalised. In this section, the first step of the anomaly detection research process---finding an appropriate problem---is formulated as an optimization problem.

To motivate our optimisation problem formulation, one can consider a stylized variant of the typical anomaly detection research process, in which a researcher equipped with a working hypothesis (in the form of a problem formulation, which associates a set of anomaly scores with each possible input from the application) is given a dataset sampled from the target application, for which she constructs a set of anomaly scores in line with her hypothesis (i.e.\ a solution to her problem formulation). She then shows her results to a domain expert, who rates them based on how well aligned he deems them to be with his notion of what is anomalous and not in the specific application. This process is iterated, with the researcher successively improving her problem formulation until the domain expert tends to agree with sufficiently well with it.

A significant share of the work involved in finding appropriate methods could be avoided if this process could be automated, and one way to automate it is to formulate it as an optimisation problem that can be algorithmically solved. To do this, the concepts presented above must be formalised.

To begin with, the sets of valid problem inputs (datasets) and outputs (solutions) must be defined. Here, we simply assume that some set $\mathcal{D}$ has been defined containing all possible datasets for the application, along with some set $\mathcal{S}$ consisting of all valid corresponding solutions.

Next, a formal description of all allowed problem formulations must be constructed. Here, we simply assume that this description consists of a set of formulae in some logic sufficiently expressive to capture all relevant problem formulation. Let us call this set $\mathcal{P}$.

The role of the domain expert can be modeled by means of an error function $\epsilon(D, S): \mathcal{D} \times \mathcal{S} \rightarrow \mathbb{R}^+$, which associates a score to any solution $S$ based on how accurately it captures the anomalies in the data $D$.

The researcher, on the other hand, really has two roles; finding a new $P$ based on the feedback from the domain expert, and computing a solution $S$ given some dataset $D$ and problem $P$. The former role corresponds to the heuristic driving the optimisation---searching the problem set $\mathcal{P}$ for an appropriate problem---and does not need be formalised yet. The latter role can be formalised as an oracle $O(P, D): \mathcal{P} \times \mathcal{D} \rightarrow \mathcal{S}$, which takes a problem $P \in \mathcal{P}$ and an input dataset $D \in \mathcal{D}$, and computes the associated solution $S \in \mathcal{S}$.

The success of $P$ in capturing the anomalies in $D$ can then be stated as $\epsilon(D, O(P, D))$. Finally, since the goal is to minimise the \emph{expected} error for datasets sampled from the given application, a random variable $X$ over $\mathcal{D}$ ought to be introduced, modelling the probability of encountering any given $D \in \mathcal{D}$. A suitable objective function would then be $\mathbb{E}_X [\epsilon(D, O(P, D))]$.

The optimisation problem can then be stated as:
\[
    P_{opt} = \argmin_{P \in \mathcal{P}}\mathbb{E}_X [ \epsilon(D, O(P, D)) ].
\]

Here, $P_{opt}$ corresponds to the best possible problem formulation, and $O(P_{opt}, D)$ to the solution of this problem for $D$.

Of course, this optimisation problem (and specifically the oracle $O$) is not tractable unless heavy restrictions are placed on the problem set $\mathcal{P}$. A major challenge is thus to find a reduced problem set $\mathcal{P}^*$ which has a tractable oracle $O^*$ and which contains a majority of interesting problem formulations.

Another problem is that it is generally not possible to compute either $\epsilon$ or $X$. Indeed, an algorithmic formulation of $\epsilon$ presupposes knowledge of the optimal problem formulation and would consequently render the optimisation process redundant. Likewise, the generation of a stream of data in accordance with $X$ would require an exact model of the underlying process, which could just as well be used directly to detect anomalies. Even if an external stream of datasets would be available, an actual domain expert would be required to represent $\epsilon$.

To get around these issues, the random vairable $X$ can be replaced with a set of labeled training data, i.e.\ a set $\mathcal{T} \subset \mathcal{D}$ in which each $T_i \in \mathcal{T}$ has an associated $s(T_i) \in \mathcal{S}$.
Correspondingly, $\epsilon(D, S)$ can then be replaced with some $\epsilon^*(T_i, S) = \delta(s(T_i), S)$, where $\delta: \mathcal{S} \times \mathcal{S} \rightarrow \mathbb{R}^+$ is some distance measure.
This approach leads to the following estimate of $P_{opt}$:
\[
    P^*_{opt} = \argmin_{P \in \mathcal{P}^*} \sum_{T_i \in \mathcal{T}} \delta(s(T_i), O^*(P, T_i)).
\]

A major focus of this report is the construction of restricted problem sets $P^*$ and corresponding tractable oracles $O^*$. In Chapter~\ref{ch:framework}, a framework for reasoning about anomaly detection problems is outlined, which can be used to construct appropriate problem sets for specific applications. This framework is then applied to sequences in Chapter~\ref{ch:time_series}, in order to construct a problem sets that generalise a majority of previously studied problem formulations for sequences while admitting a simple oracle.
