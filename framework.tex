\chapter{A Framework for Anomaly Detection}
\label{ch:framework}

In this chapter, a framework for reasoning about anomaly detection problems is presented. In this report, the framework is mainly utilised as a means of limiting the scope of the optimisation problem outlined in the previous chapter, but it is also useful as a means of relating different anomaly detection methods and finding new methods for specific applications.

A core idea of the framework is to classify and interrelate anomaly detection methods based on a few key factors. In Section~\ref{sect:the_framework}, the basic principles and motivations behind the framework are presented. In sections~\ref{sect:data_format} through~\ref{sect:output_format}, the individual factors, as well as common choices for them, are presented.

Finally, in Section~\ref{sect:related_tasks}, a few problems that are typically considered related to anomaly detection are presented in relation to the framework.

\section{Description}
\label{sect:the_framework}

As previously mentioned, the optimisation problem presented in section~\ref{sect:problem_formulation} is intractable since to the set of possible problem formulations is so large. In order to successfully apply the optimisation problem to some specific application domain, the set of problems under consideration must be restricted. However, appropriate restricted set of problems can be problematic. Ideally, such a problem set should contain all problems previously used for the specific domain, while remaining small enough to be tractable. Without some method of systematically relating problems and approaches, however, finding such a set can be complicated.

We now present a framework, using which finding an appropriate problem set can be done systematically. The key idea behind this framework is that if anomaly detection problems can be described using a few choices of standardised factors, then comparing problems, as well as restricting the problem set and finding gaps in the methods researched for applications becomes much simpler.

We here propose using the following factors to classify anomaly detection problems:
\begin{description}
  \item[Dataset format] How the datasets (method inputs) are structured.
  \item[Solution format] How the solutions (method outputs) should be structured.
  \item[Training data] What type of training data is available to methods.
  \item[Anomaly type] Which structural properties of the data should be considered.
  \item[Anomaly measure] The heuristic used to assess how anomalous items are.
\end{description}
As mentioned previously, one major advantage of an approach based on factors is that it facilitates comparisons of methods. Studying common factor choices between problems can be useful in illuminating differences and similarities. Furthermore, as we will see, specific factor choices often generalise other factor choices. Recognising this is crucial to finding general methods. Thus, the framework can be utilized to recognize when problems are similar or (partially) generalise other problems.

The remainder of this chapter deals with each of the factors presented above in turn, listing choices treated by existing methods, and introducing a few new concepts along the way.

\section{Dataset format}
\label{sect:data_format}

Obviously, the available choices of dataset format are typically heavily restricted by the application under consideration. However, transforming source datasets to some more appropriate format is a common and important task. Since the format of the data also limits the set of suitable problem definitions, selecting an appropriate format is important.

In the literature, various classifications are used to distinguish different dataset formats. In this section, a few of these are presented.

To begin with, assuming that input is given as a dataset $D = (d_1, d_2, \dots, d_n)$, where the $d_i$ belong to some set $X$, the structure of $X$ is of interest. A distinction is typically made between categorical, discrete, and real-valued datasets based on the properties of $X$. A dataset is said to be \emph{categorical} (or \emph{symbolic}) if $X$ is finite, \emph{discrete} if $X$ is countable and \emph{real-valued} if $X \subseteq \mathbb{R}^n$ for some $n$. It is also frequently the case that $X$ consists of some combination of categorical, discrete and real-valued data. In this case, $D$ is referred to as \emph{mixed}.

Categorical data arises in many contexts and is comparatively easy to handle. In many cases, methods for handling categorical data are relatively mature. For instance, categorical sequences are exhaustively treated in~\cite{TODO}. Often, there is no ordering or other relation between the elements in the underlying set, which makes the analysis simpler.

Many techniques used for categorical data (such as information-theoretic measures and certain probabilistic models) are not applicable to discrete or real-valued data. In such cases, a suitable discretisation of the underlying set might be useful. TODO: move discussion about discretisation here.

Real-valued datasets encountered in applications are often samples of processes that are assumed to be continuous. When the ordering of these samples is reflected in the dataset, the dataset is sometimes referred to as \emph{continuous}.

Anomaly detection in mixed datasets is relatively poorly understood; typically, such data is split into several separate datasets that are either categorical, discrete or real-valued before analysis.

It is fairly common to use \emph{numerosity reduction} techniques to convert discrete data to categorical data, or to compress categorical data. An example of numerosity reduction in time series is shown in figure~\ref{fig:types_of_data}.

\begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-25pt}
    \begin{center}
        \leavevmode
        \includegraphics[trim = 20mm 3mm 20mm 5mm, clip, width=0.5\textwidth]{resources/multi_vs_univariate}
    \end{center}
    \vspace{-15pt}
    \caption{{\small Two sine curves regarded as two separate univariate time series (dotted lines) and as one multivariate time series (solid lines).}}
\label{fig:multi_vs_univariate}
    \vspace{-25pt}
\end{wrapfigure}

Another important classification considers the dimensionality of the data points. A distinction is typically made between univariate and multivariate data. A dataset $D = (d_1, d_2, \dots, d_n)$ is said to be \emph{univariate} if the $d_i$ are scalars, and \emph{multivariate} if the $d_i$ are vectors of length greater than one. An illustration of uni- and multivariate time series is shown in figure~\ref{fig:multi_vs_univariate}.

\begin{figure}[htb]
\begin{center}
\leavevmode
\includegraphics[width=\textwidth]{resources/multivariate}
\end{center}
\caption{\small{An example of dimensionality reduction in a point anomaly detection problem in $R^2$. The left figure shows a set of $500$ data points $(x_i, y_i)$ containing one anomaly. The top right figure shows a histogram of the $x_i$, while the bottom right figure shows a histogram of the distance from the center point. In each figure, the location of the anomalous point is marked by an arrow. While the anomaly is easy to detect in the left and bottom right figures, it can not be seen in the top right figure. This is due to the linear inseparability of the data, and illustrates how dimensionality reduction can lead to information losses if not performed properly.}}
\label{fig:dimensionality_reduction}
\end{figure}

While the distinction between uni- and multivariate data might seem superfluous, it proves important in applications. Most machine learning methods take significantly longer to learn (both in terms of time and convergence) as the dimensions of the data increase. Furthermore, many methods are not applicable to multivariate data at all. Any multivariate dataset may be trivially split into a set of univariate datasets, something that should reasonably always be done unless there are anomalies in the multivariate dataset which are not reflected in the individual dimensions (for an example of this, see figure~\ref{fig:dimensionality_reduction}).

To mitigate the difficulties of analysing high-dimensional data, \emph{dimensionality reduction} is often performed as a pre-analysis step on multidimensional datasets. Essentially, dimensionality reduction refers to the process of transforming multidimensional data to a lower-dimensional representation, such that the aspects most pertinent to the analysis remain.

Many techniques have been designed with this goal in mind. A distinction is typically made between \emph{feature selection} and \emph{feature extraction} approaches. Feature selection approaches try to select a subset of the dimensions present in the original data. Feature extraction approaches, in contrast, transform the data into some new space, in which the relevant features are hopefully more apparent. Feature extraction methods are commonly employed as a pre-processing step in anomaly detection algorithms.

Common feature extraction methods for data in $\mathbb{R}^n$ include \emph{principle component analysis}~\cite{TODO} (PCA), \emph{semidefinite embedding}~\cite{TODO}, \emph{partial least-squares regression}~\cite{TODO}, and \emph{independent component analysis}~\cite{TODO}. Which methods are appropriate to use depends heavily on the application. An example of feature extraction is shown in figure~\ref{fig:dimensionality_reduction}.

In applications there is usually additional structure present, such as orderings or other relations between elements within datasets, that can be utilised to improve the analysis. Such additional structure is discussed in Sections~\ref{sect:anomaly_types} and~\ref{sect:anomaly_measures}.

\section{Training data}
\label{sect:training_data}

\begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-25pt}
    \begin{center}
        \leavevmode
        \includegraphics[width=0.5\textwidth]{resources/supervision}
    \end{center}
    \caption{{\small Euler diagram of the available training data for the four types of supervision.}}
\label{fig:supervision}
    \vspace{-40pt}
\end{wrapfigure}

As is customary in most areas of machine learning, anomaly detection problems are classified as either \emph{supervised}, \emph{semi-supervised} or \emph{unsupervised}~\footnote{Note that we here use the convention of~\cite{chandola}, and take supervised learning to mean that both classes of training data are available, and semi-supervised to mean that only one class of training data is available. Conventially, supervised learning is taken to mean any learning from training data, and semi-supervised learning is taken to mean that both labeled and unlabeled data is available~\cite{TODO}.} based on the availability of \emph{training} (or \emph{training}) data. In contrast to the input dataset, the training data acts as a baseline, defining what constitutes normal and anomalous.

In \emph{supervised} anomaly detection, training data containing both normal and anomalous items is available. In essence, this constitutes a traditional supervised classification problem. As such, it can be handled by any two-class classifier, such as regular support vector machines. Unfortunately, supervised approaches are usually not suitable for anomaly detection, for a few reasons. To begin with, anomalous training data is almost always relatively scarce, potentially leading to skewed classes (described in~\cite{phua} and~\cite{joshi}). Secondly, supervised anomaly detection methods are by definition unable to detect types on anomalies that are not represented in the training data, and so can not be used to find \emph{novel} anomalies. This is problematic as it is often not possible to obtain training data containing all possible anomalies.

\emph{Semi-supervised} anomaly detection, on the other hand, assumes the availability of only one class of training data. While anomaly detection with only anomalous training data has been discussed (for instance in~\cite{dasgupta}), the vast majority of semi-supervised methods assume that normal training data is available. Considering the difficulties involved in obtaining anomalous training data mentioned above, this should not be surprising. Semi-supervised methods are used more frequently than supervised methods in part due to the relative ease of producing normal training data to anomalous training data.

Finally, \emph{unsupervised} anomaly detection requires no training dataset. Since training data is not always available, unsupervised methods are typically considered to be of wider applicability than both supervised and semi-supervised methods~\cite{chandola}. However, unsupervised methods are unsuitable for certain tasks. Since training data can not be manually specified, it is more difficult to sift out uncommon but uninteresting items in unsupervised anomaly detection than in semi-supervised anomaly detection. Furthermore, unsupervised methods will not detect anomalies that are common but unexpected (although such items are arguably not anomalies by definition).

It is useful to note that unsupervised anomaly detection problems can often be reduced to semi-supervised anomaly detection problems by letting the input dataset serve as normal training data and modifying the anomaly measure such that all elements are judged as dissimilar to themselves.

Of course, it is sometimes not feasible or desirable to compare items with the entirety of the training dataset. This is mainly the case when the dataset supports additional structure, such an ordering or metric, which gives rise to a natural concept of locality within the dataset. As a concrete example of such an application, consider unsupervised anomaly detection in a long sequence: often how an item compares to those items `closest' to it (in the ordering) is much more relevant to whether or not that item should be considered an anomaly than how it compares to the rest of the sequence.

In such cases, it is reasonable to associate with each individual data item a subset of the training data, and let this subset constitute the training data for that item. Based on the discussion in~\cite{chandola}, we refer to such subsets as the \emph{contexts} of the individual data items in this report. To formalise the concept of contexts, we also introduce the concept of \emph{context functions}. For some dataset $D$, a context function is a function $C: 2^D \rightarrow 2^D$ that associates with each $D' \subset D$ some set $C(D') \subset D$ (the context of $D'$) such that $D' \cap C(D') = \emptyset$\footnote{The requirement that $D' \cap C(D') = \emptyset$ is necessary to keep elements from interfering with the computation of their own anomaly scores when performing unsupervised anomaly detection.}. As will be seen, context functions can be used to generalise many anomaly detection concepts.

\begin{figure}[thb]
    \vspace{-4pt}
    \begin{center}
        \leavevmode
        \includegraphics[width=1\textwidth]{resources/contextz}
    \end{center}
    \vspace{-15pt}
    \caption{{\small Schematic view of a dataset illustrating a few contexts. In each panel, the black dots represent selected items, the dark grey dots represent items in the context of the selected items, and the light grey dots indicate items not in the context of the selected items. The left panel shows the trivial context---all items are part of the context. The middle panel shows a local context of a single item. The right panel shows a local context of a subset of the dataset.}}
\label{fig:contexts}
    \vspace{-5pt}
\end{figure}

Consider again the example of a long sequence. Writing this sequence as $S = (s_1, s_2, \dots, s_n)$, a reasonable context function defined for individual points could be the following:
\[
    C(s_i) = \{s_{i-w}, s_{i - w + 1}, \dots, s_{i - 1}, s_{i + 1}, s_{i + 2}, \dots, s_{i + w}\}.
\]
When using this context, which is referred to as the \emph{symmetric local context}, the local characteristics of the sequence around $s_i$ are taken into account, while the rest of the sequence is ignored.

Context functions $C(d)$ defined on individual elements $d \in D$ (such as the one above) can be naturally extended to subsets $D' \subseteq D$ of the data by defining
\[
    C(D') = \bigcup_{d \in D'} C(d) \setminus D'.
\]
The context functions encountered in this report are all on this form. For this reason, there is little need to make a distinction between contexts defined for single elements and contexts defined for subsets.

Note that contexts can be seen as a generalization of the concept of training data. For instance, the \emph{trivial context}, given by, for $d \in D$; $C(d) = D \setminus d$, corresponds to traditional unsupervised anomaly detection. It is obtained when the scope of any local context grows large enough. Context functions also generalise anomaly detection problems to various tasks that have traditionally been considered separate from anomaly detection. For instance, \emph{novelty detection}, \emph{novelty detection}~\cite{chandola}, which refers to the detection of novel, or previously unseen, items or subsequences in a sequence~\footnote{It should be noted that the term `novelty detection' is occasionally used in the literature to refer to semi-supervised anomaly detection.}, is really just the use of a one-sided context $C(s_i) = \{s_{i-w}, s_{i - w + 1}, \dots, s_{i - 1}\}$ in an anomaly detection problem.

Figure~\ref{fig:contexts} shows a schematic view of a dataset, along with three contexts. The leftmost panel illustrates the trivial context of a single element, the middle panel illustrates a local context of a single element, and the rightmost panel illustrates the natural extension of this local context to subsets.

\section{Anomaly types}
\label{sect:anomaly_types}

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=1\textwidth]{resources/filters}
    \end{center}
    \caption{{\small Schematic illustration of filters and contexts acting on an evaluation sequence $S = (s_1, s_2, \dots, s_{40})$. The top panel shows the evaluation set $E = \mathcal{F}(S) = \{e_1, e_2, \dots, e_{19}\}$ extracted by a sliding window filter with width $4$ and step $2$. The bottom panel shows the local symmetric context of $e_{10}$ with width $w = 12$: $C(e_{10}) = \{c_1, c_2, \dots, c_{24}\}$, as well as the training dataset $R_{e_{10}} = \mathcal{F}_R(e_{10}) = \{r_1, r_2, \dots, r_{10}\}$ extracted by an analogous sliding window training filter.}}
\label{fig:filters}
\end{figure}

An important aspect of any problem is which subsets of the dataset $D$ to consider as potential anomalies; i.e.\ which subsets of $D$ should constitute the \emph{evaluation set} $E$. If all subsets are considered, the size $|E|$ of $E$ is $2^{|D|}$. This number is obviously too large to handle effectively, and the evaluation set must somehow be limited.

Fortunately, only a small fraction of all possible subsets is typically of interest in any given application. Precisely which subsets are interesting depends on the structure of $D = \{d_1, d_2, \dots, d_n\}$. If $D$ lacks additional structure (such as an ordering or metric) inducing a concept of locality, then it is reasonable to consider only the singleton sets, i.e. $E = \{\{d_i\} | d_i \in D\}$. When such additional structure exists (and is pertinent to the analysis), it is reasonable to let $E$ consist of subsets in which all elements are `close' (with regards to this additional structure).

As an example, consider a sequence $S = (s_1, s_2, \dots, s_n)$. As mentioned in the previous section, a locality concept is naturally induced by the sequence ordering, and it reasonable to let $E$ consist of contiguous subsequences of $S$:
\[
    E = \{(s_{a_1}, s_{a_1 + 1}, \dots , s_{b_1}) , (s_{a_2}, s_{a_2 +1}, \dots, s_{b_2}), \dots, (s_{a_k}, s_{a_k+1}, \dots, s_{b_k})\}.
\]
For such $E$, it is the case that $|E| \in O(|D|^2)$. Furthermore, it is often the case that not all contiguous subsequences must be evaluated---for instance it may suffice to treat only subsequences of some specific length, leading to $|E| \in O(|D|)$. Finally, if the ordering is not relevant to the analysis, then $E$ should be the singleton sets of $S$, and $|E| = |D|$. Thus, placing reasonable restrictions (based on the structure of the dataset) on $E$ can render the analysis much more manageable.

As a way of formalising the construction of $E$, we propose that the concepts of training and evaluation $\emph{filters}$ be introduced. Informally, these are functions from some set $X$ to some subset of the power set $2^X$ of possible subsets of $X$. An \emph{evaluation filter} is a function $\mathcal{F}_E(D): D \mapsto E \subset 2^D$ that constructs the evaluation set. One evaluation filter for sequences used later in this report is the \emph{sliding window filter}:
\[
    \mathcal{F}_E(S) = \{(s_1, s_2, \dots, s_w), (s_{s+1}, s_{s+2}, \dots, s_{s+w}), \dots, (s_{n-w}, s_{n-w+1}, \dots, c_{n})\}\footnote{It is here assumed that $ (s+w) | n$. If this is not the case, the last element extracted might be a bit different.}
\]
with width $w$ and step $s$. This filter is the most reasonable choice for sequences when all items in $E$ must be of the same length (as is typically the case).

It is further useful to, in addition to the evaluation set $E$, also construct a training set with regards to which to compare the elements in $E$. If this training set is taken to be fixed, then it can be seen as the training dataset used in a semi-supervised problem. However, we can generalise this concept to other setups by using a context function to associate different training sets with different $e_i \in E$. In this case, with each element $e_i \in E$ should be associated one such set $R_{e_i}$, consisting of subsets of the context $C(e_i)$. Analogously with evaluation filters, \emph{training filters} can be introduced, which simplify the construction of such $R_{e_i}$. Since the context is a set of sets, these should have the form $\mathcal{F}(e_i): C(e_i) \mapsto R_{e_i} \subset 2^D$. As an example of a training filter, consider the sliding window training filter for sequences with length $w$ and step $s$:
\[
    \mathcal{F}_R(e_i) = \bigcup_{(c_1, c_2, \dots, c_n) \in C(e_i)}\{(c_1, c_2, \dots, c_w), (c_{s+1}, c_{s+2}, \dots, c_{s+w}), \dots, (c_{n-w}, c_{n-w+1}, \dots, c_{n})\}.
\]

A schematic illustration of the operation on a sequence of sliding window filters and a local context is shown in Figure~\ref{fig:filters}. Here, an evaluation set consisting of $19$ subsequences of a sequence of length $40$ is constructed. With each element $e_i \in E$ is associated a training set $R_{e_i}$ (as is seen in the figure, $R_{e_{10}} = 10$). An anomaly detection algorithm could compare each of the $e_i$ to the corresponding $R_{e_i}$ in turn in order to detect contextual collective anomalies (defined below).

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=1\textwidth]{resources/types_of_anomalies}
    \end{center}
    \caption{{\small Different types of anomalies in a real-valued continuous sequence. In the middle of each series is an aberration---shaded black---corresponding to a specific type of anomaly. Appropriate contexts for these anomalies are shaded dark grey, while items not part of the contexts are shaded light grey. The top panel contains a point anomaly---a point anomalous with regard to all other points in the series. The second panel contains a contextual anomaly---a point anomalous with regard to its context (in this case, the few points preceding and succeeding it), but not necessarily to the entire series. The third panel contains a collective anomaly---a subsequence anomalous with regard to the rest of the time series. The fourth contains a contextual collective anomaly---a subsequence anomalous with regard to its context.}}
\label{fig:anomaly_types}
\end{figure}

To simplify the discussion of contexts and evaluation/training sets, we will now introduce a few different \emph{anomaly types}, inspired by the concepts of contextual and collective anomalies discussed in~\cite{chandola}. In order of increasing generality, these are \emph{point anomalies}, \emph{contextual point anomalies}, \emph{collective anomalies}, and \emph{contextual collective anomalies}. An illustration of these anomaly types in the context of real-valued sequences is shown in Figure~\ref{fig:anomaly_types}.

\emph{Point anomalies} are arguably the simplest out of these anomaly types. They correspond to single points in the dataset (i.e.\ $E$ consists of the singleton sets of $D$) that are considered anomalous with regard to the entire training set (i.e.\ a trivial context is appropriate). Point anomalies are often referred to as \emph{outliers} and arise in many domains~\cite{eskin}. Their detection is often relatively straightforward. Statistical anomaly measures have been shown to be well suited for handling point anomalies, and are often used. For certain applications, distance-based anomaly measures, such as the local outlier factor~\cite{TODO} are useful.

Of course, point anomalies are not often not sufficient to describe all anomalies when $D$ admits a concept of locality. In this case, \emph{contextual point anomalies} can capture a more general class of anomalies. Contextual anomalies are individual items that are anomalous with regards to their context (as given by some non-trivial context function); i.e.\ while they might seem normal when compared with all elements in the training data, they are anomalous when compared to the other items in their context. Formally, contextual point anomalies can be defined as, given a dataset $D$ and a context function $C(d)$, the contextual point anomalies of $D$ are the elements $d \in D$ that are point anomalies in $C(d)$. Thus, contextual point anomalies are a generalisation of point anomalies, in the sense that a point anomaly is a contextual point anomaly with regard to the trivial context $C(d) = D \setminus {d}$.

Sometimes detecting individual anomalous points $d \in D$ might not always suffice, and \emph{collective anomalies} might be required to capture relevant anomalies. Collective anomalies correspond to contiguous sets of non-anomalous points that, when taken as a whole, are anomalous with regards to the entire training set. The task of detecting such anomalies can be formulated using filters. Formally, given a set $D$ and a filter $\mathcal{F}$, the collective anomalies of $D$ are the point anomalies of $\mathcal{F}(D)$. Of course, point anomalies are a special case of collective anomalies, corresponding to the case where $\mathcal{F}(D) = D$.

Finally, \emph{contextual collective anomalies} are the most general class of anomalies, and correspond to contiguous sets of non-anomalous points that are anomalous with regard to a specific context but not to the entire training set. Formally, given a dataset $D$, a filter $\mathcal{F}$, and a context function $C$, the contextual collective anomalies of $D$ are the elements of $X \in \mathcal{F}(D)$ that are point anomalies in $C(X)$. As expected, all of the three previous anomaly types can be considered special cases of contextual collective anomalies.

An illustration of the above concepts in real-valued sequences is shown in Figure~\ref{fig:anomaly_types}. Assuming that unsupervised anomaly detection is used, Detecting point anomalies amounts to disregarding the information provided by the ordering and detecting only `rare' items. While the task can capture the aberration in the first sequence in Figure~\ref{fig:anomaly_types}, none of the aberrations in the other sequences would be considered point anomalies.

While the value at the aberrant point at the center of the second sequence occurs elsewhere in that sequence, it is anomalous with regards to its local context, and as such, should be considered a contextual point anomaly and can be captured by problem formulations that use contextual point anomalies.

Since the third time series is continuous, the aberration present at its center can not be a (contextual) point anomaly. It is, however, a collective anomaly, and can be accurately captured by problem formulations that use collective anomalies.

Finally, neither of the first three types of anomalies can capture the aberration in the fourth sequence, as it is both continuous and occurs elsewhere in the sequence. However, with an appropriate choice of (local) context, it can be deemed a contextual collective anomaly, and can be captured by problem formulations that use contextual collective anomalies.

It should be noted that while contextual point anomalies, collective anomalies, and contextual collective anomalies are all generalisations of point anomalies, it is often possible to reduce each of these anomaly types to of point anomalies, as well. As outlined above, each of these anomaly types can be defined using point anomalies. Furthermore, data normalisation be utilized to solve some contextual anomaly detection problems using point anomaly detection (see~\cite{meckesheimer}, for instance).

\section{Anomaly measures}
\label{sect:anomaly_measures}

Arguably the most significant aspect of an anomaly detection problem is the measure used to decide if items are anomalous or not. This factor defines (often in unpredictable ways) what types of features will be considered anomalous, so it is vital to choose it appropriately. Formally, an anomaly measure for some dataset $D$, given some (potentially trivial) context function $C$, can be seen as a function from some evaluation set $E \subset 2^D$ to $R^+$, that associates with each $e_i \in E$ a score according to how anomalous it is with regards to $C(e_i)$.

Many different types of anomaly measures have been used, with varying degrees of justification and success. No exhaustive presentation of these is given here; instead a selection of some of the more common approaches is presented. Two approaches that are especially interesting are statistical and information theoretic anomaly measures, since unlike most other measures, these measure admit convenient theoretical justifications.

Statistical measures usually operate under the assumption that $C(e_i)$ has been generated from some underlying distribution or stochastic process, and associates an anomaly score with $e_i$ based on how likely it is to have been generated by the same distribution or process. Typically, statistical measures work by using some standard inference method, coupled with a few assumptions about the dataset, to estimate some simple distribution underlying the $C(e_i)$. Statistical measures have been applied to a wide range of domains, often with good results. Several books and surveys have been published on the subject of anomaly detection using statistical methods~\cite{barnett}~\cite{bakar}~\cite{leroy}~\cite{hawkins}.

Statistical measures are usually classified as either parametric or non-parametric. \emph{Parametric statistical measures} assume that distribution underlying $C(e_i)$ is known, but has unknown parameters (for instance, it might be assumed that the data is $N(\mu, \sigma^2)$, where $\mu$ and $\sigma$ are unknown). \emph{Non-parametric statistical measures}, on the other hand, do not assume that the distribution is known and instead try to estimate the distribution itself by assigning weights to a set of basis functions.

While non-parametric approaches are more widely applicable (the distribution of data is usually not known), the extra information provided to parametric methods mean that they converge faster and are more accurate (as long as the given assumptions are correct). Of course, parametric methods are also less widely applicable, since the underlying distribution is often not known.

For datasets that can be modeled by stochastic processes, \emph{predictive models}, such as Markov chains~\cite{TODO}, hidden Markov models~\cite{TODO}, and autoregressive models~\cite{TODO} are frequently used as anomaly measures. It should be noted that most predictive models presuppose an ordering and a one-sided context.

Due to the relatively high computational cost of density estimation, statistical methods are mainly used to find point anomalies. Since contextual anomalies require different training sets for each $e_i \in E$, detecting contextual anomalies requires $|E|$ density estimations (unless some clever optimisation is employed), which is typically prohibitively expensive. Since most density estimation methods scale poorly with increasing dimensionality, collective anomalies can also be prohibitively expensive to detect using statistical methods.

A relatively novel and interesting class of anomaly measures is \emph{information theoretic measures}. Mainly used for symbolic datasets, these measures judge similarity by estimating how much information is shared between items or subsets of items (i.e.\ by computing measures of shared information between elements). Like statistics, information theory can be used as a theoretical basis for anomaly detection.

Several different measures of shared information have been suggested, such as the compressive-based dissimilarity measure (CDM)~\cite{keogh2} and (relative) conditional entropy~\cite{xiang}. While information theoretic approaches are mainly useful for symbolic data, they have shown promise for describing anomalies in continuous data when combined with a discretization and numerosity reduction~\cite{keogh2}.

Anomaly measures inspired by traditional machine learning methods are also common and have been extensively researched in various contexts. For instance, classifier-based methods such as support vector machines are commonly used (TODO: add citation here). While classifiers only produce as many distinct outputs as there are classes, ensembles or weighing schemes can be utilized to produce finer grained output. Like statistical anomaly measures, classifier-based anomaly measures are relatively expensive to train, so they are typically not suitable for non-trivial contexts.

Distance-based anomaly measures are also commonly used. These assign anomaly scores to elements by means of some local point density estimate. Examples include k-nearest neighbors (TODO: cite) and local outlier factor (TODO: cite). Distance-based typically measures scale well with increasing dimensionality, and are appropriate for non-trivial contexts since they are often simple to compute.

\section{Solution format}
\label{sect:output_format}

As can be expected, the expected format of solutions to an anomaly detection problem affects both the difficulty of the analysis and the usefulness of its results. As such, the choice of this factor must depend on the target presentation format and performance requirements. In this section, the most common solution formats are presented. To this end, we will consider a set of possible anomalies $A$. Depending on the filter (see Section~\ref{sect:anomaly_types}) is used, each element in $A$ can either be a subset or an element of the original (input) dataset.

In many applications, relative anomaly rankings are not essential, and a list of anomalous elements might suffice. In such cases, specifying a \emph{set of anomalous elements} as the output format might be appropriate. Essentially, this output format turns the problem of anomaly detection into a two-class classification problem, so techniques traditionally used for classification (such as support vector machines) are naturally well suited to it.

Producing a set of anomalous elements is typically appropriate when the goal of the analysis is to highlight potential anomalies to an analyst. It can also be problematic, however, since it requires some sort of threshold to be used to determine whether items are marked as anomalous or not.

A solution format that has received a lot of attention in recent years (\cite{keogh1},~\cite{bu},~\cite{yankov},~\cite{fu},~\cite{lin}) is \emph{discords}, or the set of the $k$ most anomalous elements in $A$. Since discords are less computationally intensive to produce than other solution formats, they are appropriate for analysis of very large datasets. However, discords might not be appropriate for anomaly detection in large amounts of small datasets, or for monitoring applications.

The most general solution format is to associate \emph{anomaly scores} with the elements of $A$. Typically, anomaly scores are positive real-valued numbers, and higher anomaly scores signify more anomalous elements. Of course, the fact that anomaly scores outputs have size $|A|$ means that they are comparatively computationally intensive to produce, especially if the size of $A$ is larger than the size of the original dataset. If this is the case, anomaly scores can be produced for the elements of the input dataset by weighing the anomaly scores for $A$.

While the anomaly scores of non-anomalous elements might be of little interest, producing them can still be useful for visualisation purposes. Furthermore, both of the previously mentioned solution formats can be constructed from anomaly scores, which makes anomaly scores especially useful when the output requirements are not clear.
