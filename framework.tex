\chapter{A Framework for Anomaly Detection}
\label{ch:framework}

In this chapter, a framework for reasoning about anomaly detection problems is presented. In this report, the framework is mainly utilised as a means of limiting the scope of the optimisation problem outlined in the previous chapter, but it is also useful as a means of relating different anomaly detection methods and finding new methods for specific applications.

A core idea of the framework is to classify and interrelate anomaly detection methods based on a few key factors. In Section~\ref{sect:the_framework}, the basic principles and motivations behind the framework are presented. In sections~\ref{sect:data_format} through~\ref{sect:output_format}, the individual factors, as well as common choices for them, are presented.

Finally, in Section~\ref{sect:related_tasks}, a few problems that are typically considered related to anomaly detection are presented in relation to the framework.

\section{Description}
\label{sect:the_framework}

As previously mentioned, the optimisation problem presented in section~\ref{sect:problem_formulation} is intractable since to the set of possible problem formulations is so large. In order to successfully apply the optimisation problem to some specific application domain, the set of problems under consideration must be restricted. However, appropriate restricted set of problems can be problematic. Ideally, such a problem set should contain all problems previously used for the specific domain, while remaining small enough to be tractable. Without some method of systematically relating problems and approaches, however, finding such a set can be complicated.

We now present a framework, using which finding an appropriate problem set can be done systematically. The key idea behind this framework is that if anomaly detection problems can be described using a few choices of standardised factors, then comparing problems, as well as restricting the problem set and finding gaps in the methods researched for applications becomes much simpler.

We here propose using the following factors to classify anomaly detection problems:
\begin{description}
  \item[Dataset format] How the datasets (method inputs) are structured.
  \item[Solution format] How the solutions (method outputs) should be structured.
  \item[Training data] What type of training data is available to methods.
  \item[Anomaly type] Which structural properties of the data should be considered.
  \item[Anomaly measure] The heuristic used to assess how anomalous items are.
\end{description}
As mentioned previously, one major advantage of an approach based on factors is that it facilitates comparisons of methods. Studying common factor choices between problems can be useful in illuminating differences and similarities. Furthermore, as we will see, specific factor choices often generalise other factor choices. Recognising this is crucial to finding general methods. Thus, the framework can be utilized to recognize when problems are similar or (partially) generalise other problems.

The remainder of this chapter deals with each of the factors presented above in turn, listing choices treated by existing methods, and introducing a few new concepts along the way.

\section{Dataset format}
\label{sect:data_format}

Obviously, the available choices of dataset format are typically heavily restricted by the application under consideration. However, transforming source datasets to some more appropriate format is a common and important task. Since the format of the data also limits the set of suitable problem definitions, selecting an appropriate format is important.

In the literature, various classifications are used to distinguish different dataset formats. In this section, a few of these are presented.

To begin with, assuming that input is given as a data set $D = (d_1, d_2, \dots, d_n)$, where the $d_i$ belong to some set $X$, the structure of $X$ is of interest. A distinction is typically made between categorical, discrete, and real-valued datasets based on the properties of $X$. A dataset is said to be \emph{categorical} (or \emph{symbolic}) if $X$ is finite, \emph{discrete} if $X$ is countable and \emph{real-valued} if $X \subseteq \mathbb{R}^n$ for some $n$. It is also frequently the case that $X$ consists of some combination of categorical, discrete and real-valued data. In this case, $D$ is referred to as \emph{mixed}.

Categorical (or \emph{symbolic}) data arises in many contexts and is comparatively easy to handle. In many cases, methods for handling categorical data are relatively mature. For instance, categorical sequences are exhaustively treated in~\cite{TODO}. Often, there is no ordering or other relation between the elements in the underlying set, which makes the analysis simpler.

Many techniques used for categorical data (such as information-theoretic measures and certain probabilistic models) are not applicable to discrete or real-valued data. In such cases, a suitable discretisation of the underlying set might be useful. TODO: move discussion about discretisation here.

Real-valued data sets encountered in applications are often samples of processes that are assumed to be continuous. When the ordering of these samples is reflected in the data set, the dataset is sometimes referred to as \emph{continuous}.

Anomaly detection in mixed datasets is relatively poorly understood; typically, such data is split into several separate datasets that are either categorical, discrete or real-valued before analysis.

It is fairly common to use \emph{numerosity reduction} techniques to convert discrete data to categorical data, or to compress categorical data. TODO: put numerosity reduction discussion here

Another important classification considers the dimensionality of the data points. A distinction is typically made between univariate and multivariate data. A dataset $D = (d_1, d_2, \dots, d_n)$ is said to be \emph{univariate} if the $d_i$ are scalars, and \emph{multivariate} if the $d_i$ are vectors of length greater than one.

While the distinction between uni- and multivariate data might seem superfluous, it proves important in applications. Most machine learning methods take significantly longer to learn (both in terms of time and convergence) as the dimensions of the data increase. Furthermore, many methods are not applicable to multivariate data at all.

To mitigate the difficulties of analysing high-dimensional data, \emph{dimensionality reduction} is often performed as a pre-analysis step on multidimensional datasets. TODO: put dimensionality reduction discussion here.

In applications there is usually additional structure present, such as orderings or other relations between elements within datasets, that can be utilised to improve the analysis. Such additional structure is discussed in Sections~\ref{sect:anomaly_types} and~\ref{sect:anomaly_measures}.

\clearpage

\section{Training data}
\label{sect:training_data}

\begin{wrapfigure}{r}{0.5\textwidth}
    \vspace{-25pt}
    \begin{center}
        \leavevmode
        \includegraphics[width=0.5\textwidth]{resources/supervision}
    \end{center}
    \caption{{\small Euler diagram of the available training data for the four types of supervision.}}
\label{fig:supervision}
    \vspace{-40pt}
\end{wrapfigure}

As is customary in most areas of machine learning, anomaly detection problems are classified as either \emph{supervised}, \emph{semi-supervised} or \emph{unsupervised} based on the availability of \emph{training} (or \emph{training}) data. In contrast to the \emph{evaluation data}, which is the data in which anomalies are to be found, the training data acts as a baseline, defining what constitutes normal and/or anomalous. The three classes of training data are now discussed and presented as tasks, starting with supervised anomaly detection:

\begin{task}[Supervised anomaly detection]
\label{task:supervised}\ \\
    Given training sets $N$ (containing normal training data) and $A$ (containing anomalous training data), find anomalies (with regard to $N$ and $A$) in a data set $D$.
\end{task}
In essence, supervised anomaly detection constitutes a traditional supervised classification problem. As such, it can be handled by any two-class classifier, such as regular support vector machines. However, characteristics shared by most anomaly detection applications make supervised approaches unsuitable.

First, anomalous training data is almost always relatively scarce, potentially leading to skewed classes (described in~\cite{phua} and~\cite{joshi}). Furthermore, supervised anomaly detection methods are by definition unable to detect types on anomalies that are not represented in $A$, and so can not be used to find \emph{novel} anomalies. This is problematic as it is often not feasible to construct an $A$ containing all possible anomalies.

Semi-supervised anomaly detection, on the other hand, assumes the availability of either only $A$ or only $N$. Divided according to which of the two training classes is available, the following two tasks can be specified:
\begin{task}[Semi-supervised anomaly detection with normal training data]
  Given a training set $N$ containing normal training data, find anomalies (with regard to $N$) in a data set $D$.
\end{task}
\begin{task}[Semi-supervised anomaly detection with anomalous training data]
\label{task:semisupervised_anomaly_detection}
  Given a training set $A$ containing anomalous training data, find anomalies (with regard to $A$) in a data set $D$.
\end{task}

While the latter task has been discussed (for instance in~\cite{dasgupta}), the vast majority of methods focus on the former. Considering the difficulties involved in obtaining anomalous training data, as mentioned above, this should not be surprising.

Semi-supervised methods are often used more frequently than supervised methods due to the relative ease with which they can be configured.

Finally, unsupervised anomaly detection requires no training data set, and can be defined by the following task:
\begin{task}[Unsupervised anomaly detection]
\label{task:unsupervised_anomaly_detection}
  Find subsets of some data set $D$ that are anomalous with regard to the rest of $D$.
\end{task}

For unsupervised anomaly detection, $D$ itself is referred to as the training data.

Since training data is not always available, unsupervised methods are typically considered to be of wider applicability than both supervised and semi-supervised methods~\cite{chandola}. However, unsupervised methods are unsuitable for certain tasks. Since training data can not be manually specified, it is more difficult to sift out uncommon but uninteresting items in unsupervised anomaly detection than in semi-supervised anomaly detection. Furthermore, unsupervised methods will not detect anomalies that are common but unexpected (although such items are arguably not anomalies by definition).

It is useful to note that unsupervised anomaly detection tasks can often be reduced to semi-supervised anomaly detection tasks by setting $A = D$ and modifying the underlying anomaly measure such that all elements $a_i \in A$ are judged as dissimilar to themselves.

Of course, it is sometimes not feasible or desirable to compare items with the entirety of the training data set. This is mainly the case when the data set supports additional structure, such an ordering or metric, which gives rise to a natural concept of locality within the data set. As a concrete example of such an application, consider unsupervised anomaly detection in a long sequence: often how an item compares to those items `closest' to it (in the ordering) is much more relevant to whether or not that item should be considered an anomaly than how it compares to the rest of the sequence.

In such cases, it is reasonable to associate with each individual data item a subset of the training data, and let this subset constitute the training data for that item. Throughout this report, such subsets will be referred to as the \emph{contexts} of the individual data items. Formally, this can be represented through a \emph{context function} that maps each subset $D'$ of the data set (or at least those subsets of interest to the analysis) to some set $C(D')$ such that $D' \cap C(D') = \emptyset$. The requirement that $D' \cap C(D') = \emptyset$ is necessary to keep elements from lowering their own anomaly scores when performing unsupervised anomaly detection. For the purposes of this report, contexts are mainly interesting for unsupervised anomaly detection, and can henceforth be assumed to refer to subsets of the evaluation data unless explicitly stated.

\begin{figure}[thb]
    \vspace{-4pt}
    \begin{center}
        \leavevmode
        \includegraphics[width=1\textwidth]{resources/contextz}
    \end{center}
    \vspace{-15pt}
    \caption{{\small Schematic view of a data set illustrating a few contexts. In each panel, the black dots represent selected items, the dark grey dots represent items in the context of the selected items, and the light grey dots indicate items not in the context of the selected items. The left panel shows the trivial context---all items are part of the context. The middle panel shows a local context of a single item. The right panel shows a local context of a subset of the data set.}}
\label{fig:contexts}
    \vspace{-5pt}
\end{figure}

Consider again the example of a long sequence. Writing this sequence as $S = (s_1, s_2, \dots, s_n)$, a reasonable context function defined for individual points could be the following:
\[
    C(s_i) = \{s_{i-w}, s_{i - w + 1}, \dots, s_{i - 1}, s_{i + 1}, s_{i + 2}, \dots, s_{i + w}\}.
\]
When using this context, which is referred to as the \emph{symmetric local context}, the local characteristics of the sequence around $s_i$ are taken into account, while the rest of the sequence is ignored.

Context functions $C(d)$ defined on individual elements $d \in D$ (such as the one above) can be naturally extended to subsets $D' \subseteq D$ of the data by defining
\[
    C(D') = \bigcup_{d \in D'} C(d) \setminus D'.
\]
The context functions encountered in this report are all on this form. For this reason, there is little need to make a distinction between contexts defined for single elements and contexts defined for subsets.

Note that contexts can be seen as a generalization of the concept of training data. For instance, the \emph{trivial context}, given by, for $d \in D$; $C(d) = D \setminus d$, corresponds to unsupervised anomaly detection. It is obtained when the scope of any local context grows large enough.

Figure~\ref{fig:contexts} shows a schematic view of a data set, along with three contexts. The leftmost panel illustrates the trivial context of a single element, the middle panel illustrates a local context of a single element, and the rightmost panel illustrates the natural extension of this local context to subsets.

\section{Anomaly types}
\label{sect:anomaly_types}

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=1\textwidth]{resources/filters}
    \end{center}
    \caption{{\small Schematic illustration of filters and contexts acting on an evaluation sequence $S = (s_1, s_2, \dots, s_{40})$. The top panel shows the evaluation set $E = \mathcal{F}(S) = \{e_1, e_2, \dots, e_{19}\}$ extracted by a sliding window filter with width $4$ and step $2$. The bottom panel shows the local symmetric context of $e_{10}$ with width $w = 12$: $C(e_{10}) = \{c_1, c_2, \dots, c_{24}\}$, as well as the training data set $R_{e_{10}} = \mathcal{F}_R(e_{10}) = \{r_1, r_2, \dots, r_{10}\}$ extracted by an analogous sliding window training filter.}}
\label{fig:filters}
\end{figure}

An important aspect of any problem is which subsets of the data set $D$ to consider when looking for anomalies; i.e.\ which subsets of $D$ should constitute the \emph{evaluation set} $E$. If all subsets are considered, the size $|E|$ of $E$ is $2^{|D|}$. This number is obviously too large to handle effectively, and the evaluation set must somehow be limited.

Fortunately, only a small fraction of all possible subsets is typically of interest in any given application. Precisely which subsets are interesting depends on the structure of $D = \{d_1, d_2, \dots, d_n\}$. If $D$ lacks additional structure (such as an ordering or metric) inducing a concept of locality, then it is reasonable to consider only the singleton sets, i.e. $E = \{\{d_i\} | d_i \in D\}$. When such additional structure exists (and is pertinent to the analysis), it is reasonable to let $E$ consist of subsets in which all elements are `close' (with regards to this additional structure).

As an example, consider a sequence $S = (s_1, s_2, \dots, s_n)$. As mentioned in the previous section, a locality concept is naturally induced by the sequence ordering, and it reasonable to let $E$ consist of contiguous subsequences of $S$:
\[
    E = \{(s_{a_1}, s_{a_1 + 1}, \dots , s_{b_1}) , (s_{a_2}, s_{a_2 +1}, \dots, s_{b_2}), \dots, (s_{a_k}, s_{a_k+1}, \dots, s_{b_k})\}.
\]
For such $E$, it is the case that $|E| \in O(|D|^2)$. Furthermore, it is often the case that not all contiguous subsequences must be evaluated---for instance it may suffice to treat only subsequences of some specific length, leading to $|E| \in O(|D|)$. Finally, if the ordering is not relevant to the analysis, then $E$ should be the singleton sets of $S$, and $|E| = |D|$. Thus, placing reasonable restrictions (based on the structure of the data set) on $E$ can render the analysis much more manageable.

To facilitate the construction of $E$, the concept of $\emph{filters}$ can be used. An \emph{evaluation filter} is a function $\mathcal{F}_E(D): D \mapsto E \subset 2^D$ that constructs the evaluation set. One evaluation filter for sequences used extensively in this report is the \emph{sliding window filter}:
\[
    \mathcal{F}_E(S) = \{(s_1, s_2, \dots, s_w), (s_{s+1}, s_{s+2}, \dots, s_{s+w}), \dots, (s_{n-w}, s_{n-w+1}, \dots, c_{n})\}\footnote{It is here assumed that $ (s+w) | n$. If this is not the case, the last element extracted might be a bit different.}
\]
with width $w$ and step $s$. This filter is the most reasonable choice for sequences when all items in $E$ must be of the same length (as is typically the case).

Of course, it is often reasonable to, in addition to the evaluation set $E$, also construct a training set, with regards to which to compare the elements in $E$. Naturally, with each element $e_i \in E$ should be associated one such set $R_{e_i}$, consisting of subsets of the context $C(e_i)$. Analogously with evaluation filters, \emph{training filters} can be introduced, which simplify the construction of such $R_{e_i}$. Since the context is a set of sets, these should have the form $\mathcal{F}(e_i): C(e_i) \mapsto R_{e_i} \subset 2^D$. As an example of a training filter, consider the sliding window training filter for sequences with length $w$ and step $s$:
\[
    \mathcal{F}_R(e_i) = \bigcup_{(c_1, c_2, \dots, c_n) \in C(e_i)}\{(c_1, c_2, \dots, c_w), (c_{s+1}, c_{s+2}, \dots, c_{s+w}), \dots, (c_{n-w}, c_{n-w+1}, \dots, c_{n})\}.
\]

A schematic illustration of the operation on a sequence of sliding window filters and a local context is shown in Figure~\ref{fig:filters}. Here, an evaluation set consisting of $19$ subsequences of a sequence of length $40$ is constructed. With each element $e_i \in E$ is associated a training set $R_{e_i}$ (as is seen in the figure, $R_{e_{10}} = 10$). An anomaly detection algorithm could compare each of the $e_i$ to the corresponding $R_{e_i}$ in turn in order to detect contextual collective anomalies (defined below).

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=1\textwidth]{resources/types_of_anomalies}
    \end{center}
    \caption{{\small Different types of anomalies in a real-valued continuous sequence. In the middle of each series is an aberration---shaded black---corresponding to a specific type of anomaly. Appropriate contexts for these anomalies are shaded dark grey, while items not part of the contexts are shaded light grey. The top panel contains a point anomaly---a point anomalous with regard to all other points in the series. The second panel contains a contextual anomaly---a point anomalous with regard to its context (in this case, the few points preceding and succeeding it), but not necessarily to the entire series. The third panel contains a collective anomaly---a subsequence anomalous with regard to the rest of the time series. The fourth contains a contextual collective anomaly---a subsequence anomalous with regard to its context.}}
\label{fig:anomaly_types}
\end{figure}

To simplify the discussion of contexts and evaluation/training sets, it is helpful to introduce a few different \emph{anomaly types}, based on which appropriate choices of evaluation and training filters can be inferred. For the purposes of the discussion in this report, an introduction of four anomaly types will suffice. In order of increasing generality, these are \emph{point anomalies}, \emph{contextual point anomalies}, \emph{collective anomalies}, and \emph{contextual collective anomalies}. An illustration of these anomaly types in the context of real-valued sequences is shown in Figure~\ref{fig:anomaly_types}.

\emph{Point anomalies} are arguably the simplest out of these anomaly types. They correspond to single points in the data set (i.e.\ $E$ consists of the singleton sets of $D$) that are considered anomalous with regard to the entire training set (i.e.\ a trivial context is appropriate). Finding them can be formulated as the following task:

\begin{task}[Point anomaly detection]
\label{task:point}
  Given a data set $D$, detect individual $d_i \in D$ that are anomalous with regard to the entire training set.
\end{task}

Point anomalies are often referred to as \emph{outliers} and arise in many domains~\cite{eskin}. Their detection is often relatively straightforward. Statistical methods have been shown to be well suited for handling point anomalies, and are usually sufficient.

Of course, point anomalies are not often not sufficient to describe all anomalies when $D$ admits a concept of locality. In this case, \emph{contextual point anomalies} can capture a more general class of anomalies. Contextual anomalies are individual items that are anomalous with regards to their context (as given by some non-trivial context function); i.e.\ while they might seem normal when compared with all elements in the training data, they are anomalous when compared to the other items in their context. Detecting contextual point anomalies can be formulated as the following task:

\begin{task}[Contextual anomaly detection]
\label{task:contextual}
  Given a set $D$ and a non-trivial context function $C(d)$, detect elements $d \in D$ anomalous with regards to $C(d)$.
\end{task}

Furthermore, detecting individual anomalous points $d \in D$ might not always suffice (specifically, when the anomalies are continuous), and \emph{collective anomalies} might be required to capture relevant phenomena. These correspond to contiguous sets of non-anomalous points that, when taken as a whole, are anomalous with regards to the entire training set (i.e.\ a trivial context is appropriate). The task of detecting such anomalies can be formulated using filters:

\begin{task}[Collective anomaly detection]
\label{task:collective}
  Given a set $D$ and a (non-singleton) filter $\mathcal{F}$, detect point anomalies in the evaluation set $\mathcal{F}(D)$.
\end{task}

Finally, \emph{contextual collective anomalies} are the most general class of anomalies, and correspond to contiguous sets of non-anomalous points that are anomalous with regard to a specific context but not to the entire training set.

\begin{task}[Contextual collective anomaly detection]
\label{task:contextual_power}
  Given a data set $D$, a (non-singular) filter $\mathcal{F}$ and a non-trivial context function $C$, detect elements $e_i$ in the evaluation set $\mathcal{F}(D)$ that are anomalous with regards to the context $C(e_i)$.
\end{task}

An illustration of the above concepts in real-valued sequences is shown in Figure~\ref{fig:anomaly_types}. Assuming that unsupervised anomaly detection is used, Task~\ref{task:point} amounts to disregarding the information provided by the ordering and detecting only `rare' items. While the task can capture the aberration in the first sequence in Figure~\ref{fig:anomaly_types}, none of the aberrations in the other sequences would be considered point anomalies.

While the value at the aberrant point at the center of the second sequence occurs elsewhere in that sequence, it is anomalous with regards to its local context, and as such, should be considered a contextual point anomaly and can be captured by Task~\ref{task:contextual}.

Since the third time series is continuous, the aberration present at its center can not be captured by Tasks~\ref{task:point} Or~\ref{task:contextual}. It is, however, a collective anomaly, and can be accurately captured by Task~\ref{task:collective}.

Finally, neither of the Tasks~\ref{task:point},~\ref{task:contextual} or~\ref{task:collective} captures the aberration in the fourth sequence, as it is both continuous and occurs elsewhere in the sequence. However, with an appropriate choice of (local) context, it can be deemed a contextual collective anomaly, and can be captured by Task~\ref{task:contextual_power}.

It should be noted that while all of the above tasks are special cases of contextual collective anomaly detection, it is often possible to reduce each of the tasks to detection of point anomalies, as well. Task~\ref{task:collective} reduces to detection of point anomalies by its definition (i.e.\ it corresponds to detecting point anomalies in a higher-dimensional space), while data normalization can sometimes be utilized to perform this reduction for contextual anomaly detection (see~\cite{meckesheimer} for instance).

\section{Anomaly measures}
\label{sect:anomaly_measures}

Arguably the most significant aspect of an anomaly detection method is what heuristic is used to decide if items are anomalous or not. This choice defines (often in unpredictable ways) what types of features will be considered anomalous, so it is vital to make an appropriate choice.

Many heuristics have been proposed in the literature, with varying degrees of justification and success. No exhaustive presentation of these is given here; instead a selection of some of the more common approaches is presented. We begin by describing statistical and information theoretic approaches---two areas which provide theoretic justifications for what should be considered anomalous. We then present a few other approaches taken from traditional machine learning.

Statistical measures usually address the following task:
\begin{task}[Statistical anomaly detection]
\label{task:statistical}
  Given a data set $D$, find items $d \in D$ that are unlikely to have been generated by the same distribution as the rest of $D$ (or some training set $R$).
\end{task}
In general, statistical measures work by estimating a statistical distribution underlying the data, and then labeling data points based on how likely they are to have been generated by this distribution. They have been applied to a wide range of domains, often with good results. Several books and surveys have been published on statistical anomaly detection, including~\cite{barnett},~\cite{bakar},~\cite{leroy} and~\cite{hawkins}.

Statistical measures are usually classified based on whether the distribution is known in advance (with unknown parameters) or not. We formulate these two cases as the following two tasks:
\begin{task}[Parametric statistical anomaly detection]
  Given a data set $D$, generated from the distribution $\mathcal{D}(\theta)$ with the unknown parameter $\theta$, estimate $\theta$ based on $D$ (or some training data set $R$), and find items $d \in D$ that are unlikely to have been generated by $\mathcal{D}(\theta)$.
\end{task}
\begin{task}[Non-parametric statistical anomaly detection]
  Given a data set $D$, estimate the distribution $\mathcal{D}$ of $D$ (or some training data set) from a set of basis functions and find items $d \in D$ that are unlikely to have been generated by $\mathcal{D}$.
\end{task}
While non-parametric approaches are more widely applicable (the distribution of data is usually not known), the extra information provided to parametric methods mean that they converge faster and are more accurate. Both these statistical tasks suffer from scalability issues. Furthermore, it can be difficult to modify statistical methods to take context into account.

A relatively novel and interesting approach to anomaly measures is \emph{information theoretic measures}. Mainly used for symbolic data sets, these measures judge similarity by estimating how much information is shared between items or subsets of items (i.e.\ by computing measures of shared information between elements). Like statistics, information theory can be used to give a theoretical justification for what is considered anomalous.

Several different measures of shared information have been implemented, such as the compressive-based dissimilarity measure (CDM)~\cite{keogh2} and (relative) conditional entropy~\cite{xiang}. While information theoretic approaches are mainly useful for discrete data, they have shown promise for describing anomalies in continuous data when combined with a discretization transformation~\cite{keogh2}. Information theoretical anomaly detection can be summarized as the following task:

\begin{task}[Information theoretic anomaly detection]
  Given a data set $D$, find items in $D$ that share little information with the rest of $D$ (or some training data set).
\end{task}

Anomaly measures inspired by traditional machine learning are also common and have been extensively researched in various contexts. We here present two tasks, using classifier-based and point-based measures, which together cover a majority of the methods proposed in the literature. We begin by introducing classifier-based measures:

\begin{task}[Classifier-based anomaly detection]
  Given a data set $D$, train a two-class classifier and use this classifier to determine whether or not the elements in $D$ are anomalous.
\end{task}

While classifiers are commonly used with Task~\ref{task:anomalous_set}, weighing schemes can be utilized to produce other forms of output. Depending on the type of training data, different types of classifiers must be used. Semi-supervised problems require one-class classifiers, while unsupervised methods require unsupervised classifiers. Furthermore, classifiers that do not support iterative addition and removal of elements can not be used for unsupervised anomaly detection.

Another common approach is distance-based heuristics:
\begin{task}[Distance-based anomaly detection]
  Given a data set $D \subset X$ for some set $X$ and a distance measure $\delta(d_i, d_j): X \times X \rightarrow \mathbb{R}$, determine if the $d_i \in D$ are anomalous or not based on $\delta(d_i, d_j)$ for $d_j \in D, i \neq j$.
\end{task}
Obviously, such measures are not always applicable, since they require $X$ to allow some form of useful distance function. Derived problem formulations often base their anomaly measures on the local point density of or the distances to the few nearest points in the training set around evaluated points. Such methods include \emph{k-nearest neighbors} (kNN) and, more generally, \emph{variable kernel density estimation}.

This task is very flexible, since any distance measure be used, and the distance values so obtained can be utilized in many ways. It is also well suited for both semi-supervised and unsupervised anomaly detection.

In some situations, it is useful to build a predictive model:
\begin{task}[Detecting anomalies based on a predictive model]
\label{task:predictive_model}
  Given a sequence $S$, build a model that predicts the next state based on the previous states. Determine if each $s_i \in S$ is an anomaly or not based on how much it diverges from the value predicted by the model.
\end{task}
Models that have been studied include Markov chains, hidden Markov models, autoregressive models, as well as several others.

While the above tasks cover a majority of methods in the literature, several heuristics not covered by them have been proposed. Furthermore, there is often overlap between these tasks. For instance, most predictive models used in Task~\ref{task:predictive_model} are based on statistical measures, and problems using such models could just as well be said to target Task~\ref{task:statistical}

\section{Solution format}
\label{sect:output_format}

As can be expected, the expected format of solutions to an anomaly detection problem affects both the difficulty of the analysis and the usefulness of its results. As such, the choice of this factor must depend on the target presentation format and performance requirements. In this section, the most common solution formats are presented. To this end, we will consider a set of possible anomalies $A$. Depending on the filter (see Section~\ref{sect:anomaly_types}) is used, each element in $A$ can either be a subset or an element of the original (input) dataset.

In many applications, relative anomaly rankings are not essential, and a list of anomalous elements might suffice. In such cases, specifying a \emph{set of anomalous elements} as the output format might be appropriate. Essentially, this output format turns the problem of anomaly detection into a two-class classification problem, so techniques traditionally used for classification (such as support vector machines) are naturally well suited to it.

Producing a set of anomalous elements is typically appropriate when the goal of the analysis is to highlight potential anomalies to an analyst. It can also be problematic, however, since it requires some sort of threshold to be used to determine whether items are marked as anomalous or not.

A solution format that has received a lot of attention in recent years (\cite{keogh1},~\cite{bu},~\cite{yankov},~\cite{fu},~\cite{lin}) is \emph{discords}, or the set of the $k$ most anomalous elements in $A$. Since discords are less computationally intensive to produce than other solution formats, they are appropriate for analysis of very large data sets. However, discords might not be appropriate for anomaly detection in large amounts of small datasets, or for monitoring applications.

The most general solution format is to associate \emph{anomaly scores} with the elements of $A$. Typically, anomaly scores are positive real-valued numbers, and higher anomaly scores signify more anomalous elements. Of course, the fact that anomaly scores outputs have size $|A|$ means that they are comparatively computationally intensive to produce, especially if the size of $A$ is larger than the size of the original dataset. If this is the case, anomaly scores can be produced for the elements of the input dataset by weighing the anomaly scores for $A$.

While the anomaly scores of non-anomalous elements might be of little interest, producing them can still be useful for visualisation purposes. Furthermore, both of the previously mentioned solution formats can be constructed from anomaly scores, which makes anomaly scores especially useful when the output requirements are not clear.

\section{Related high-level tasks}
\label{sect:related_tasks}

Anomaly detection is closely related to several other problems in data mining, machine learning and signal processing. We here briefly present a few high-level tasks, analogous to Task~\ref{task:anomaly_detection}, for a few such problems.

There are multiple related problems in signal processing that involve the detection and removal of anomalies in data. Typically referred to as \emph{noise removal}, \emph{data cleaning}~\cite{meckesheimer}, or \emph{signal recovery}, these problems are summarized in the following task:
\begin{task}[Signal detection]
  Given a data set $D$ consisting of a relevant signal with added noise, remove all anomalies caused by the noise.
\end{task}

\emph{Novelty detection}~\cite{chandola} refers to the detection of novel, or previously unseen, items or subsequences in a sequence~\footnote{It should be noted that the term `novelty detection' is occasionally used in the literature to refer to semi-supervised anomaly detection.}, as formalized by the following task:
\begin{task}[Novelty detection]
\label{task:novelty_detection}
  Given a sequence $S$, detect subsequences $(s_i, s_{i+1}, \dots, s_j) \subset S$ that are anomalous with regards to earlier subsequences (i.e. $(s_i, s_{i+1}, \dots, s_j) \subset S$ for $k < i$ and $l < j$).
\end{task}
Most of the high-level tasks presented in this chapter can be combined with novelty detection, which is reasonable considering that it can be reduced to Task~\ref{task:contextual_power} through the choice of an appropriate context function. It is especially interesting when used in monitoring applications and in the context of long sequences.

\emph{Change detection} (or \emph{event detection}) is the problem of detecting points at which sequences change in some way.
\begin{task}[Change detection]
      Given a sequence $S$, detect points at which the underlying distribution or model generating the $s_i$ changes.
\end{task}
Change detection is almost exclusively associated with time series, and has been used mainly in the study of climate data~\cite{gopala} and image analysis~\cite{radke}.

Other tasks that are often interesting in the same contexts as anomaly detection include \emph{clustering}~\cite{clustering} and \emph{motif discovery}~\cite{motif}~\cite{motif2}.

